{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "036adfe8ee224a55a0889737fbe48ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c8f1d95149d4f6bb0330258f6af0ea4",
            "placeholder": "​",
            "style": "IPY_MODEL_23accb572c764ac7b18aaf1af6a022b9",
            "value": " 3.94k/3.94k [00:00&lt;00:00, 136kB/s]"
          }
        },
        "03db147f01564aa296358bc650be3916": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0463e1b8507441b79e996f73c68a40d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7823b6ffcef94222be1cdca2c661ed04",
            "placeholder": "​",
            "style": "IPY_MODEL_42bb16d7389d43a9b5506130fe4e09d7",
            "value": "Downloading: 100%"
          }
        },
        "0c63469be3a142f792f69b14984e7747": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11a14e14654949a6a173916989bd43c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce901c41bdda40bab37c224822f022b0",
            "placeholder": "​",
            "style": "IPY_MODEL_ddbe5279fc04449188695375d7f33d52",
            "value": " 1.31M/1.31M [00:00&lt;00:00, 3.88MB/s]"
          }
        },
        "153620a44c88414a8e610c6af1de0267": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_400069c8a6ef476a9332d0ea9b9ef20f",
            "max": 4039,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c573a8b0fb5b4e87be558da9d3be2fdf",
            "value": 4039
          }
        },
        "2248e00287784cf1b86ed8715237db44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97701990ecc845edb80abcdffe1c5132",
            "placeholder": "​",
            "style": "IPY_MODEL_5a4782ab72c54304a8e33e9425ef11fa",
            "value": "Downloading: 100%"
          }
        },
        "23accb572c764ac7b18aaf1af6a022b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "275766ea5f4c4f45981ca38bc3d30468": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d1d42edbe264d6198c59cac8ecb7895": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3291292ee663463ca940ffe5c4ea4ae5",
              "IPY_MODEL_69b48c289d13413f80ee55cbad95573e",
              "IPY_MODEL_fe85185c1e59439f9a5d85b36fcd2ef9"
            ],
            "layout": "IPY_MODEL_55d0e59062594eabb7f24dab156e2a94"
          }
        },
        "2fe206d674494389b1c75b0b1b95d2b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "305666fe63b4480ca886654e3e953264": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdb865c784844112b89ce813f0bef9e0",
            "max": 826,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_645cdc9531c344e7a941b0ec7721e336",
            "value": 826
          }
        },
        "3291292ee663463ca940ffe5c4ea4ae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d013898ae9cf4a7ca007d281cbd7d28d",
            "placeholder": "​",
            "style": "IPY_MODEL_ba0d9af23cdd4885a9cab57472221fa2",
            "value": "Downloading: 100%"
          }
        },
        "3515b382d154416e98bdee3444e34179": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3800f430b1f94524b30eb7ffbc49ef91": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3907b4fe14cd40d9b03216a3ed10f386": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a24869dd7db4e409613a25a99b2e84f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e929c00f3f1421cae759e562581c743": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03db147f01564aa296358bc650be3916",
            "max": 456356,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc2c477786ad4528b8d16454040d3345",
            "value": 456356
          }
        },
        "400069c8a6ef476a9332d0ea9b9ef20f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "418c131375324b88b70bb93aca6461db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42bb16d7389d43a9b5506130fe4e09d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c4afa08ac034ca59f47ed27c452562b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d313423a8b746d2bd9deab3d10237b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4f915b1dfb3643649e0d31ac00d43fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2248e00287784cf1b86ed8715237db44",
              "IPY_MODEL_edc42778a7824d89b1bbd36ac9da256f",
              "IPY_MODEL_7045f8e1ea5e4725aa002c61063117dd"
            ],
            "layout": "IPY_MODEL_3a24869dd7db4e409613a25a99b2e84f"
          }
        },
        "525ad55300cc449691535b5469ec0c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1f09aab70884cf3b6a7dbc8c3dee490",
            "placeholder": "​",
            "style": "IPY_MODEL_3800f430b1f94524b30eb7ffbc49ef91",
            "value": "Downloading: 100%"
          }
        },
        "541d272569e34fa893e1f1192621b585": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2aab4900a1d4035a4e9a32f438b4b60",
              "IPY_MODEL_8f8ada3ce83340baa656583f7b7e2800",
              "IPY_MODEL_929515722de84dfeb333a94185c09d69"
            ],
            "layout": "IPY_MODEL_da9dbb3284524884b0e4f9298c665297"
          }
        },
        "54234e3b446e4f4b865f76b9fdafce01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55d0e59062594eabb7f24dab156e2a94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a4782ab72c54304a8e33e9425ef11fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "645cdc9531c344e7a941b0ec7721e336": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67bc335a6d2f4672a0f66f6c05974e39": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69b48c289d13413f80ee55cbad95573e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c4afa08ac034ca59f47ed27c452562b",
            "max": 357,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c65f8696241f426bb295bda31d4ad667",
            "value": 357
          }
        },
        "6c8f1d95149d4f6bb0330258f6af0ea4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c9bfc504cfe4cdaa347a40bf730070a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f1e1e5e5ce9420399904b7c34bb0c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6fd25c7d836d4f88abfd352b0995ce95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7045f8e1ea5e4725aa002c61063117dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee2a498700c247cd80208d8b0910d058",
            "placeholder": "​",
            "style": "IPY_MODEL_2fe206d674494389b1c75b0b1b95d2b3",
            "value": " 619/619 [00:00&lt;00:00, 20.9kB/s]"
          }
        },
        "706bdb7d967947ddbe94febcb4a8ae6f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71b10878e239477a9f314372621ad021": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73cfe65490cc492f8f61cb88a9e084f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7823b6ffcef94222be1cdca2c661ed04": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e1fc6a38569457cb717db7b41aebd52": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "838f070e33af470fb753fe130aa19f96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b1515ae411e48f88e75dbde1bc4b0f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b243dfd4ed24b699d674900f45ad195": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_525ad55300cc449691535b5469ec0c22",
              "IPY_MODEL_305666fe63b4480ca886654e3e953264",
              "IPY_MODEL_b0d135b0a1cd49f4bae49e128b37803c"
            ],
            "layout": "IPY_MODEL_a867a214610e450cbcfd59da53052edc"
          }
        },
        "8f8ada3ce83340baa656583f7b7e2800": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_706bdb7d967947ddbe94febcb4a8ae6f",
            "max": 798156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a99bea0476c7470b90192bf7838ebf6a",
            "value": 798156
          }
        },
        "8ff0230a260c4a15a54b70f9b7b25884": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9fbe0e0845be4b2ba73bf01c40f7b157",
              "IPY_MODEL_3e929c00f3f1421cae759e562581c743",
              "IPY_MODEL_a4eeb1a8a4874b31917e04fe18db5ecb"
            ],
            "layout": "IPY_MODEL_275766ea5f4c4f45981ca38bc3d30468"
          }
        },
        "929515722de84dfeb333a94185c09d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e80f1246b4264ec28e748d60e638821d",
            "placeholder": "​",
            "style": "IPY_MODEL_0c63469be3a142f792f69b14984e7747",
            "value": " 779k/779k [00:00&lt;00:00, 921kB/s]"
          }
        },
        "96193485918d42918bcb991becd7f3c2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97701990ecc845edb80abcdffe1c5132": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fbe0e0845be4b2ba73bf01c40f7b157": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54234e3b446e4f4b865f76b9fdafce01",
            "placeholder": "​",
            "style": "IPY_MODEL_a25b27da7e664c7eb289e6735b5459dd",
            "value": "Downloading: 100%"
          }
        },
        "a25b27da7e664c7eb289e6735b5459dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2aab4900a1d4035a4e9a32f438b4b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fd25c7d836d4f88abfd352b0995ce95",
            "placeholder": "​",
            "style": "IPY_MODEL_8b1515ae411e48f88e75dbde1bc4b0f1",
            "value": "Downloading: 100%"
          }
        },
        "a4eeb1a8a4874b31917e04fe18db5ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71b10878e239477a9f314372621ad021",
            "placeholder": "​",
            "style": "IPY_MODEL_4d313423a8b746d2bd9deab3d10237b5",
            "value": " 446k/446k [00:00&lt;00:00, 765kB/s]"
          }
        },
        "a867a214610e450cbcfd59da53052edc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a99bea0476c7470b90192bf7838ebf6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae3127a7feea4e7eb84298ffb057ace2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3515b382d154416e98bdee3444e34179",
            "max": 1373465,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6f1e1e5e5ce9420399904b7c34bb0c09",
            "value": 1373465
          }
        },
        "b0d135b0a1cd49f4bae49e128b37803c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_838f070e33af470fb753fe130aa19f96",
            "placeholder": "​",
            "style": "IPY_MODEL_3907b4fe14cd40d9b03216a3ed10f386",
            "value": " 826/826 [00:00&lt;00:00, 25.7kB/s]"
          }
        },
        "b3723a3e712849899e2242a39c517648": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0463e1b8507441b79e996f73c68a40d6",
              "IPY_MODEL_153620a44c88414a8e610c6af1de0267",
              "IPY_MODEL_036adfe8ee224a55a0889737fbe48ff4"
            ],
            "layout": "IPY_MODEL_7e1fc6a38569457cb717db7b41aebd52"
          }
        },
        "b639299a491f429ba70c2f959194fba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4833007b9284e18a84f648e3b36aa05",
            "placeholder": "​",
            "style": "IPY_MODEL_418c131375324b88b70bb93aca6461db",
            "value": "Downloading: 100%"
          }
        },
        "b9a0a9b919e14c51a844df7b0550da5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b639299a491f429ba70c2f959194fba5",
              "IPY_MODEL_ae3127a7feea4e7eb84298ffb057ace2",
              "IPY_MODEL_11a14e14654949a6a173916989bd43c1"
            ],
            "layout": "IPY_MODEL_67bc335a6d2f4672a0f66f6c05974e39"
          }
        },
        "ba0d9af23cdd4885a9cab57472221fa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc2c477786ad4528b8d16454040d3345": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4833007b9284e18a84f648e3b36aa05": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c573a8b0fb5b4e87be558da9d3be2fdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c65f8696241f426bb295bda31d4ad667": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce901c41bdda40bab37c224822f022b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d013898ae9cf4a7ca007d281cbd7d28d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da9dbb3284524884b0e4f9298c665297": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddbe5279fc04449188695375d7f33d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e80f1246b4264ec28e748d60e638821d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed61ae1802d64ee5a7b59e8ece23f470": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edc42778a7824d89b1bbd36ac9da256f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96193485918d42918bcb991becd7f3c2",
            "max": 619,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73cfe65490cc492f8f61cb88a9e084f3",
            "value": 619
          }
        },
        "ee2a498700c247cd80208d8b0910d058": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1f09aab70884cf3b6a7dbc8c3dee490": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdb865c784844112b89ce813f0bef9e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe85185c1e59439f9a5d85b36fcd2ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed61ae1802d64ee5a7b59e8ece23f470",
            "placeholder": "​",
            "style": "IPY_MODEL_6c9bfc504cfe4cdaa347a40bf730070a",
            "value": " 357/357 [00:00&lt;00:00, 11.5kB/s]"
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install bitsandbytes\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zo2di_L042N",
        "outputId": "b38a302a-e1bb-4430-b88d-5283c309d4a7",
        "execution": {
          "iopub.status.busy": "2023-05-15T09:15:59.024480Z",
          "iopub.execute_input": "2023-05-15T09:15:59.025023Z",
          "iopub.status.idle": "2023-05-15T09:16:39.278963Z",
          "shell.execute_reply.started": "2023-05-15T09:15:59.024991Z",
          "shell.execute_reply": "2023-05-15T09:16:39.277618Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.28.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.3.23)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.11.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting bitsandbytes\n  Downloading bitsandbytes-0.38.1-py3-none-any.whl (104.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.38.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (1.5.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.64.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (10.0.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.4.0)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.13.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.28.2)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (2.1.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (22.2.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.8.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.11.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import transformers\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.cuda.amp import custom_fwd, custom_bwd\n",
        "\n",
        "from bitsandbytes.functional import quantize_blockwise, dequantize_blockwise\n",
        "\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "bX35XMqY1JfY",
        "execution": {
          "iopub.status.busy": "2023-05-15T09:16:50.028616Z",
          "iopub.execute_input": "2023-05-15T09:16:50.029028Z",
          "iopub.status.idle": "2023-05-15T09:16:55.438762Z",
          "shell.execute_reply.started": "2023-05-15T09:16:50.028993Z",
          "shell.execute_reply": "2023-05-15T09:16:55.437799Z"
        },
        "trusted": true,
        "outputId": "78a8ab0d-4796-427e-af19-49393b5939b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\n===================================BUG REPORT===================================\nWelcome to bitsandbytes. For bug reports, please run\n\npython -m bitsandbytes\n\n and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n================================================================================\nbin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so\nCUDA SETUP: CUDA runtime path found: /opt/conda/lib/libcudart.so.11.0\nCUDA SETUP: Highest compute capability among GPUs detected: 7.5\nCUDA SETUP: Detected CUDA version 117\nCUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/lib/x86_64-linux-gnu'), PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/cuda/lib')}\n  warn(msg)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quatization**"
      ],
      "metadata": {
        "id": "EKti6sXNG4H5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FrozenBNBLinear(nn.Module):\n",
        "    def __init__(self, weight, absmax, code, bias=None):\n",
        "        assert isinstance(bias, nn.Parameter) or bias is None\n",
        "        super().__init__()\n",
        "        self.out_features, self.in_features = weight.shape\n",
        "        self.register_buffer(\"weight\", weight.requires_grad_(False))\n",
        "        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n",
        "        self.register_buffer(\"code\", code.requires_grad_(False))\n",
        "        self.adapter = None\n",
        "        self.bias = bias\n",
        " \n",
        "    def forward(self, input):\n",
        "        output = DequantizeAndLinear.apply(input, self.weight, self.absmax, self.code, self.bias)\n",
        "        if self.adapter:\n",
        "            output_cloned = torch.clone(output + self.adapter(input))\n",
        "            return output_cloned\n",
        "        else :\n",
        "            return output\n",
        " \n",
        "    @classmethod\n",
        "    def from_linear(cls, linear: nn.Linear) -> \"FrozenBNBLinear\":\n",
        "        weights_int8, state = quantize_blockise_lowmemory(linear.weight)\n",
        "        return cls(weights_int8, *state, linear.bias)\n",
        " \n",
        "    def __repr__(self):\n",
        "        return f\"{self.__class__.__name__}({self.in_features}, {self.out_features})\"\n",
        " \n",
        " \n",
        "class DequantizeAndLinear(torch.autograd.Function): \n",
        "    @staticmethod\n",
        "    @custom_fwd\n",
        "    def forward(ctx, input: torch.Tensor, weights_quantized: torch.ByteTensor,\n",
        "                absmax: torch.FloatTensor, code: torch.FloatTensor, bias: torch.FloatTensor):\n",
        "        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n",
        "        ctx.save_for_backward(input, weights_quantized, absmax, code)\n",
        "        ctx._has_bias = bias is not None\n",
        "        return F.linear(input, weights_deq, bias).clone()\n",
        " \n",
        "    @staticmethod\n",
        "    @custom_bwd\n",
        "    def backward(ctx, grad_output: torch.Tensor):\n",
        "        assert not ctx.needs_input_grad[1] and not ctx.needs_input_grad[2] and not ctx.needs_input_grad[3]\n",
        "        input, weights_quantized, absmax, code = ctx.saved_tensors\n",
        "        # grad_output: [*batch, out_features]\n",
        "        weights_deq = dequantize_blockwise(weights_quantized, absmax=absmax, code=code)\n",
        "        grad_input = grad_output @ weights_deq\n",
        "        grad_bias = grad_output.flatten(0, -2).sum(dim=0) if ctx._has_bias else None\n",
        "        return grad_input, None, None, None, grad_bias\n",
        " \n",
        " \n",
        "class FrozenBNBEmbedding(nn.Module):\n",
        "    def __init__(self, weight, absmax, code):\n",
        "        super().__init__()\n",
        "        self.num_embeddings, self.embedding_dim = weight.shape\n",
        "        self.register_buffer(\"weight\", weight.requires_grad_(False))\n",
        "        self.register_buffer(\"absmax\", absmax.requires_grad_(False))\n",
        "        self.register_buffer(\"code\", code.requires_grad_(False))\n",
        "        self.adapter = None\n",
        " \n",
        "    def forward(self, input, **kwargs):\n",
        "        with torch.no_grad():\n",
        "            # note: both quantuized weights and input indices are *not* differentiable\n",
        "            weight_deq = dequantize_blockwise(self.weight, absmax=self.absmax, code=self.code)\n",
        "            output = F.embedding(input, weight_deq, **kwargs)\n",
        "        \n",
        "        if self.adapter:\n",
        "            output_cloned = torch.clone(output + self.adapter(input))\n",
        "            return output_cloned\n",
        "        else :\n",
        "            return output\n",
        " \n",
        "    @classmethod\n",
        "    def from_embedding(cls, embedding: nn.Embedding) -> \"FrozenBNBEmbedding\":\n",
        "        weights_int8, state = quantize_blockise_lowmemory(embedding.weight)\n",
        "        return cls(weights_int8, *state)\n",
        " \n",
        "    def __repr__(self):\n",
        "        return f\"{self.__class__.__name__}({self.num_embeddings}, {self.embedding_dim})\"\n",
        " \n",
        " \n",
        "def quantize_blockise_lowmemory(matrix: torch.Tensor, chunk_size: int = 2 ** 20):\n",
        "    assert chunk_size % 4096 == 0\n",
        "    code = None\n",
        "    chunks = []\n",
        "    absmaxes = []\n",
        "    flat_tensor = matrix.view(-1)\n",
        "    for i in range((matrix.numel() - 1) // chunk_size + 1):\n",
        "        input_chunk = flat_tensor[i * chunk_size: (i + 1) * chunk_size].clone()\n",
        "        quantized_chunk, (absmax_chunk, code) = quantize_blockwise(input_chunk, code=code)\n",
        "        chunks.append(quantized_chunk)\n",
        "        absmaxes.append(absmax_chunk)\n",
        " \n",
        "    matrix_i8 = torch.cat(chunks).reshape_as(matrix)\n",
        "    absmax = torch.cat(absmaxes)\n",
        "    return matrix_i8, (absmax, code)\n",
        " \n",
        " \n",
        "def convert_to_int8(model):\n",
        "    \"\"\"Convert linear and embedding modules to 8-bit with optional adapters\"\"\"\n",
        "    for module in list(model.modules()):\n",
        "        for name, child in module.named_children():\n",
        "            if isinstance(child, nn.Linear):\n",
        "                print(name, child)\n",
        "                setattr(\n",
        "                    module,\n",
        "                    name,\n",
        "                    FrozenBNBLinear(\n",
        "                        weight=torch.zeros(child.out_features, child.in_features, dtype=torch.uint8),\n",
        "                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n",
        "                        code=torch.zeros(256),\n",
        "                        bias=child.bias,\n",
        "                    ),\n",
        "                )\n",
        "            elif isinstance(child, nn.Embedding):\n",
        "                setattr(\n",
        "                    module,\n",
        "                    name,\n",
        "                    FrozenBNBEmbedding(\n",
        "                        weight=torch.zeros(child.num_embeddings, child.embedding_dim, dtype=torch.uint8),\n",
        "                        absmax=torch.zeros((child.weight.numel() - 1) // 4096 + 1),\n",
        "                        code=torch.zeros(256),\n",
        "                    )\n",
        "                )"
      ],
      "metadata": {
        "id": "bVLaOT811bVo",
        "execution": {
          "iopub.status.busy": "2023-05-15T09:17:03.567453Z",
          "iopub.execute_input": "2023-05-15T09:17:03.568096Z",
          "iopub.status.idle": "2023-05-15T09:17:03.600944Z",
          "shell.execute_reply.started": "2023-05-15T09:17:03.568060Z",
          "shell.execute_reply": "2023-05-15T09:17:03.599835Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTJBlock(transformers.models.gptj.modeling_gptj.GPTJBlock):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "\n",
        "        convert_to_int8(self.attn)\n",
        "        convert_to_int8(self.mlp)\n",
        "\n",
        "\n",
        "class GPTJModel(transformers.models.gptj.modeling_gptj.GPTJModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        convert_to_int8(self)\n",
        "        \n",
        "\n",
        "class GPTJForCausalLM(transformers.models.gptj.modeling_gptj.GPTJForCausalLM):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        convert_to_int8(self)\n",
        "\n",
        "\n",
        "transformers.models.gptj.modeling_gptj.GPTJBlock = GPTJBlock"
      ],
      "metadata": {
        "id": "xtafVIQn1gcl",
        "execution": {
          "iopub.status.busy": "2023-05-15T09:17:12.893706Z",
          "iopub.execute_input": "2023-05-15T09:17:12.894133Z",
          "iopub.status.idle": "2023-05-15T09:17:20.627233Z",
          "shell.execute_reply.started": "2023-05-15T09:17:12.894099Z",
          "shell.execute_reply": "2023-05-15T09:17:20.626213Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class T5ForConditionalGeneration(transformers.models.t5.modeling_t5.T5ForConditionalGeneration):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        convert_to_int8(self)\n",
        "\n",
        "transformers.models.t5.modeling_t5.T5ForConditionalGeneration = T5ForConditionalGeneration"
      ],
      "metadata": {
        "id": "Y1q4P6av8e3k",
        "execution": {
          "iopub.status.busy": "2023-05-15T09:17:20.632737Z",
          "iopub.execute_input": "2023-05-15T09:17:20.634963Z",
          "iopub.status.idle": "2023-05-15T09:17:20.647902Z",
          "shell.execute_reply.started": "2023-05-15T09:17:20.634928Z",
          "shell.execute_reply": "2023-05-15T09:17:20.646895Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = transformers.GPTJConfig.from_pretrained(\"EleutherAI/gpt-j-6B\")\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "8b243dfd4ed24b699d674900f45ad195",
            "a867a214610e450cbcfd59da53052edc",
            "525ad55300cc449691535b5469ec0c22",
            "305666fe63b4480ca886654e3e953264",
            "b0d135b0a1cd49f4bae49e128b37803c",
            "3800f430b1f94524b30eb7ffbc49ef91",
            "f1f09aab70884cf3b6a7dbc8c3dee490",
            "645cdc9531c344e7a941b0ec7721e336",
            "fdb865c784844112b89ce813f0bef9e0",
            "3907b4fe14cd40d9b03216a3ed10f386",
            "838f070e33af470fb753fe130aa19f96",
            "4f915b1dfb3643649e0d31ac00d43fb7",
            "3a24869dd7db4e409613a25a99b2e84f",
            "2248e00287784cf1b86ed8715237db44",
            "edc42778a7824d89b1bbd36ac9da256f",
            "7045f8e1ea5e4725aa002c61063117dd",
            "5a4782ab72c54304a8e33e9425ef11fa",
            "97701990ecc845edb80abcdffe1c5132",
            "73cfe65490cc492f8f61cb88a9e084f3",
            "96193485918d42918bcb991becd7f3c2",
            "2fe206d674494389b1c75b0b1b95d2b3",
            "ee2a498700c247cd80208d8b0910d058",
            "541d272569e34fa893e1f1192621b585",
            "da9dbb3284524884b0e4f9298c665297",
            "a2aab4900a1d4035a4e9a32f438b4b60",
            "8f8ada3ce83340baa656583f7b7e2800",
            "929515722de84dfeb333a94185c09d69",
            "8b1515ae411e48f88e75dbde1bc4b0f1",
            "6fd25c7d836d4f88abfd352b0995ce95",
            "a99bea0476c7470b90192bf7838ebf6a",
            "706bdb7d967947ddbe94febcb4a8ae6f",
            "0c63469be3a142f792f69b14984e7747",
            "e80f1246b4264ec28e748d60e638821d",
            "8ff0230a260c4a15a54b70f9b7b25884",
            "275766ea5f4c4f45981ca38bc3d30468",
            "9fbe0e0845be4b2ba73bf01c40f7b157",
            "3e929c00f3f1421cae759e562581c743",
            "a4eeb1a8a4874b31917e04fe18db5ecb",
            "a25b27da7e664c7eb289e6735b5459dd",
            "54234e3b446e4f4b865f76b9fdafce01",
            "bc2c477786ad4528b8d16454040d3345",
            "03db147f01564aa296358bc650be3916",
            "4d313423a8b746d2bd9deab3d10237b5",
            "71b10878e239477a9f314372621ad021",
            "b9a0a9b919e14c51a844df7b0550da5b",
            "67bc335a6d2f4672a0f66f6c05974e39",
            "b639299a491f429ba70c2f959194fba5",
            "ae3127a7feea4e7eb84298ffb057ace2",
            "11a14e14654949a6a173916989bd43c1",
            "418c131375324b88b70bb93aca6461db",
            "c4833007b9284e18a84f648e3b36aa05",
            "6f1e1e5e5ce9420399904b7c34bb0c09",
            "3515b382d154416e98bdee3444e34179",
            "ddbe5279fc04449188695375d7f33d52",
            "ce901c41bdda40bab37c224822f022b0",
            "b3723a3e712849899e2242a39c517648",
            "7e1fc6a38569457cb717db7b41aebd52",
            "0463e1b8507441b79e996f73c68a40d6",
            "153620a44c88414a8e610c6af1de0267",
            "036adfe8ee224a55a0889737fbe48ff4",
            "42bb16d7389d43a9b5506130fe4e09d7",
            "7823b6ffcef94222be1cdca2c661ed04",
            "c573a8b0fb5b4e87be558da9d3be2fdf",
            "400069c8a6ef476a9332d0ea9b9ef20f",
            "23accb572c764ac7b18aaf1af6a022b9",
            "6c8f1d95149d4f6bb0330258f6af0ea4",
            "2d1d42edbe264d6198c59cac8ecb7895",
            "55d0e59062594eabb7f24dab156e2a94",
            "3291292ee663463ca940ffe5c4ea4ae5",
            "69b48c289d13413f80ee55cbad95573e",
            "fe85185c1e59439f9a5d85b36fcd2ef9",
            "ba0d9af23cdd4885a9cab57472221fa2",
            "d013898ae9cf4a7ca007d281cbd7d28d",
            "c65f8696241f426bb295bda31d4ad667",
            "4c4afa08ac034ca59f47ed27c452562b",
            "6c9bfc504cfe4cdaa347a40bf730070a",
            "ed61ae1802d64ee5a7b59e8ece23f470",
            "4487003de6384b67badb187fc72a80d9",
            "9297f9bca1a74cc2b3db5fdae866be59",
            "8ed32a71e70b47fb818f76b842b50494",
            "8c5c5b7a80b94ffd8935804df71117e7",
            "1be0bf91ddbd47108223f91d20d6f04d",
            "31c0934a09a64d5cbae2c69475b5954a",
            "cf59cb9712054c8c976b1c79339e1092"
          ]
        },
        "id": "qwJixCub1uwI",
        "outputId": "01d4bc5a-ee8a-47be-a943-4815a950d855",
        "execution": {
          "iopub.status.busy": "2023-05-15T09:17:25.198427Z",
          "iopub.execute_input": "2023-05-15T09:17:25.198779Z",
          "iopub.status.idle": "2023-05-15T09:17:28.775093Z",
          "shell.execute_reply.started": "2023-05-15T09:17:25.198750Z",
          "shell.execute_reply": "2023-05-15T09:17:28.774172Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/930 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4487003de6384b67badb187fc72a80d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9297f9bca1a74cc2b3db5fdae866be59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ed32a71e70b47fb818f76b842b50494"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c5c5b7a80b94ffd8935804df71117e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.37M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1be0bf91ddbd47108223f91d20d6f04d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)in/added_tokens.json:   0%|          | 0.00/4.04k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31c0934a09a64d5cbae2c69475b5954a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/357 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf59cb9712054c8c976b1c79339e1092"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config.pad_token_id = config.eos_token_id\n",
        "tokenizer.pad_token = config.pad_token_id"
      ],
      "metadata": {
        "id": "y0SXSVLk1zh_",
        "execution": {
          "iopub.status.busy": "2023-05-15T09:17:33.508117Z",
          "iopub.execute_input": "2023-05-15T09:17:33.508488Z",
          "iopub.status.idle": "2023-05-15T09:17:33.515652Z",
          "shell.execute_reply.started": "2023-05-15T09:17:33.508459Z",
          "shell.execute_reply": "2023-05-15T09:17:33.512672Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt = GPTJForCausalLM.from_pretrained(\"hivemind/gpt-j-6B-8bit\", low_cpu_mem_usage=True)\n",
        "#gpt = GPTJForCausalLM.from_pretrained(\"gustavecortal/fr-boris-8bit\", low_cpu_mem_usage=True) French GPT-J Cedille's Boris"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "bba4093e71bd4fdd841aec6bc9478d7e",
            "5260d956a2654b128a2be51fab25cc8a"
          ]
        },
        "id": "bYYH1l2hHhFZ",
        "outputId": "79247244-d9d0-4023-c743-fb6148f1662d",
        "execution": {
          "iopub.status.busy": "2023-05-15T09:17:37.485935Z",
          "iopub.execute_input": "2023-05-15T09:17:37.486785Z",
          "iopub.status.idle": "2023-05-15T09:19:15.514886Z",
          "shell.execute_reply.started": "2023-05-15T09:17:37.486739Z",
          "shell.execute_reply": "2023-05-15T09:19:15.513271Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bba4093e71bd4fdd841aec6bc9478d7e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/6.18G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5260d956a2654b128a2be51fab25cc8a"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "k_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nk_proj Linear(in_features=4096, out_features=4096, bias=False)\nv_proj Linear(in_features=4096, out_features=4096, bias=False)\nq_proj Linear(in_features=4096, out_features=4096, bias=False)\nout_proj Linear(in_features=4096, out_features=4096, bias=False)\nfc_in Linear(in_features=4096, out_features=16384, bias=True)\nfc_out Linear(in_features=16384, out_features=4096, bias=True)\nlm_head Linear(in_features=4096, out_features=50400, bias=True)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():  \n",
        "    dev = \"cuda:0\" \n",
        "else:  \n",
        "    dev = \"cpu\"  \n",
        "device = torch.device(dev)  \n",
        "\n",
        "gpt.to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-15T09:20:10.585055Z",
          "iopub.execute_input": "2023-05-15T09:20:10.585926Z",
          "iopub.status.idle": "2023-05-15T09:20:16.884843Z",
          "shell.execute_reply.started": "2023-05-15T09:20:10.585890Z",
          "shell.execute_reply": "2023-05-15T09:20:16.883896Z"
        },
        "trusted": true,
        "id": "xKCcX6t1cuk6",
        "outputId": "d106a75b-5677-4076-a284-26428fcfddd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 9,
          "output_type": "execute_result",
          "data": {
            "text/plain": "GPTJForCausalLM(\n  (transformer): GPTJModel(\n    (wte): FrozenBNBEmbedding(50400, 4096)\n    (drop): Dropout(p=0.0, inplace=False)\n    (h): ModuleList(\n      (0-27): 28 x GPTJBlock(\n        (ln_1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (attn): GPTJAttention(\n          (attn_dropout): Dropout(p=0.0, inplace=False)\n          (resid_dropout): Dropout(p=0.0, inplace=False)\n          (k_proj): FrozenBNBLinear(4096, 4096)\n          (v_proj): FrozenBNBLinear(4096, 4096)\n          (q_proj): FrozenBNBLinear(4096, 4096)\n          (out_proj): FrozenBNBLinear(4096, 4096)\n        )\n        (mlp): GPTJMLP(\n          (fc_in): FrozenBNBLinear(4096, 16384)\n          (fc_out): FrozenBNBLinear(16384, 4096)\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): FrozenBNBLinear(4096, 50400)\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import csv\n",
        "# Load dataset\n",
        "df = pd.read_csv('/kaggle/input/nlpgettingstarted/train.csv')\n",
        "df = df[['text', 'target']]\n",
        "df = df.rename(columns={'text': 'input_text', 'target': 'label'})\n",
        "# Split dataset into training and test sets\n",
        "train_data, test_data = train_test_split(df, test_size=0.8, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-15T11:38:53.854101Z",
          "iopub.execute_input": "2023-05-15T11:38:53.855087Z",
          "iopub.status.idle": "2023-05-15T11:38:53.893769Z",
          "shell.execute_reply.started": "2023-05-15T11:38:53.855053Z",
          "shell.execute_reply": "2023-05-15T11:38:53.892760Z"
        },
        "trusted": true,
        "id": "LBdRTGAEcuk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate model\n",
        "train_data1 = train_data['input_text'].to_list()\n",
        "y_train_data = train_data['label'].astype(str).to_list()\n",
        "test_data = test_data[['input_text', 'label']]\n",
        "y_test_data = test_data['label'].to_list()\n",
        "\n",
        "# Encodage des données d'entraînement avec le tokenizer\n",
        "model_inputs = tokenizer(train_data1, padding=True, truncation=True, max_length=128, return_tensors='pt').to(device)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-15T11:38:58.391320Z",
          "iopub.execute_input": "2023-05-15T11:38:58.391684Z",
          "iopub.status.idle": "2023-05-15T11:38:59.329830Z",
          "shell.execute_reply.started": "2023-05-15T11:38:58.391655Z",
          "shell.execute_reply": "2023-05-15T11:38:59.328818Z"
        },
        "trusted": true,
        "id": "zil4ZwFucuk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Automatic Prompt Engineer (APE)**"
      ],
      "metadata": {
        "id": "anal_dK6cuk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Dependencies\n",
        "! pip install git+https://github.com/keirp/automatic_prompt_engineer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-15T09:21:16.829891Z",
          "iopub.execute_input": "2023-05-15T09:21:16.830310Z",
          "iopub.status.idle": "2023-05-15T09:21:39.391930Z",
          "shell.execute_reply.started": "2023-05-15T09:21:16.830277Z",
          "shell.execute_reply": "2023-05-15T09:21:39.390711Z"
        },
        "trusted": true,
        "id": "6_orQxa3cuk8",
        "outputId": "4e3f3cd2-b6ea-4195-8096-2a6afada19d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nCollecting git+https://github.com/keirp/automatic_prompt_engineer\n  Cloning https://github.com/keirp/automatic_prompt_engineer to /tmp/pip-req-build-q70tvh_v\n  Running command git clone --filter=blob:none --quiet https://github.com/keirp/automatic_prompt_engineer /tmp/pip-req-build-q70tvh_v\n  Resolved https://github.com/keirp/automatic_prompt_engineer to commit 21080cca80a688b0de6953f6eaa8f0fc6f2bc630\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from automatic-prompt-engineer==1.0) (1.23.5)\nCollecting openai\n  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: fire in /opt/conda/lib/python3.10/site-packages (from automatic-prompt-engineer==1.0) (0.5.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from automatic-prompt-engineer==1.0) (4.64.1)\nCollecting gradio\n  Downloading gradio-3.30.0-py3-none-any.whl (17.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire->automatic-prompt-engineer==1.0) (1.16.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire->automatic-prompt-engineer==1.0) (2.2.0)\nRequirement already satisfied: websockets>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (11.0.2)\nCollecting semantic-version\n  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (4.5.0)\nRequirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (0.25.1)\nRequirement already satisfied: aiofiles in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (22.1.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (6.0)\nRequirement already satisfied: huggingface-hub>=0.13.0 in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (0.13.4)\nRequirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (0.21.1)\nCollecting python-multipart\n  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (2.28.2)\nRequirement already satisfied: orjson in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (3.8.10)\nRequirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (1.10.7)\nCollecting ffmpy\n  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting httpx\n  Downloading httpx-0.24.0-py3-none-any.whl (75 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.3/75.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting mdit-py-plugins<=0.3.3\n  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (0.95.0)\nCollecting gradio-client>=0.2.4\n  Downloading gradio_client-0.2.4-py3-none-any.whl (287 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.9/287.9 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (3.8.4)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (3.1.2)\nRequirement already satisfied: markupsafe in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (2.1.2)\nRequirement already satisfied: altair>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (4.2.2)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (9.5.0)\nRequirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (2.2.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (3.6.3)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (1.5.3)\nRequirement already satisfied: pygments>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from gradio->automatic-prompt-engineer==1.0) (2.15.0)\nRequirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from altair>=4.2.0->gradio->automatic-prompt-engineer==1.0) (0.4)\nRequirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair>=4.2.0->gradio->automatic-prompt-engineer==1.0) (4.17.3)\nRequirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair>=4.2.0->gradio->automatic-prompt-engineer==1.0) (0.12.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio-client>=0.2.4->gradio->automatic-prompt-engineer==1.0) (21.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client>=0.2.4->gradio->automatic-prompt-engineer==1.0) (2023.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.13.0->gradio->automatic-prompt-engineer==1.0) (3.11.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio->automatic-prompt-engineer==1.0) (0.1.2)\nCollecting linkify-it-py<3,>=1\n  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->gradio->automatic-prompt-engineer==1.0) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->gradio->automatic-prompt-engineer==1.0) (2023.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->gradio->automatic-prompt-engineer==1.0) (2022.12.7)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->gradio->automatic-prompt-engineer==1.0) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->gradio->automatic-prompt-engineer==1.0) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->gradio->automatic-prompt-engineer==1.0) (1.26.15)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio->automatic-prompt-engineer==1.0) (0.14.0)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio->automatic-prompt-engineer==1.0) (8.1.3)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio->automatic-prompt-engineer==1.0) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio->automatic-prompt-engineer==1.0) (1.8.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio->automatic-prompt-engineer==1.0) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio->automatic-prompt-engineer==1.0) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio->automatic-prompt-engineer==1.0) (22.2.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->gradio->automatic-prompt-engineer==1.0) (4.0.2)\nRequirement already satisfied: starlette<0.27.0,>=0.26.1 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio->automatic-prompt-engineer==1.0) (0.26.1)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio->automatic-prompt-engineer==1.0) (1.3.0)\nCollecting httpcore<0.18.0,>=0.15.0\n  Downloading httpcore-0.17.0-py3-none-any.whl (70 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio->automatic-prompt-engineer==1.0) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio->automatic-prompt-engineer==1.0) (1.4.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio->automatic-prompt-engineer==1.0) (1.0.7)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio->automatic-prompt-engineer==1.0) (4.39.3)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->gradio->automatic-prompt-engineer==1.0) (3.0.9)\nRequirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio->automatic-prompt-engineer==1.0) (3.6.2)\nRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->automatic-prompt-engineer==1.0) (0.19.3)\nCollecting uc-micro-py\n  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\nBuilding wheels for collected packages: automatic-prompt-engineer, ffmpy\n  Building wheel for automatic-prompt-engineer (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for automatic-prompt-engineer: filename=automatic_prompt_engineer-1.0-py3-none-any.whl size=16667 sha256=7df53a81220faf7122c311f0d877f37d899383c87f7b11a33b91bc3ab040529e\n  Stored in directory: /tmp/pip-ephem-wheel-cache-icbe7h13/wheels/10/3a/96/9bfca882d75855c6df75391d5e867dba4e4ac7ec3133bceac1\n  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4712 sha256=5a583d66e422b20bf527f50862549879867a8fa7611cd0a5e562eac94c3c65bc\n  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\nSuccessfully built automatic-prompt-engineer ffmpy\nInstalling collected packages: ffmpy, uc-micro-py, semantic-version, python-multipart, mdit-py-plugins, linkify-it-py, httpcore, openai, httpx, gradio-client, gradio, automatic-prompt-engineer\n  Attempting uninstall: mdit-py-plugins\n    Found existing installation: mdit-py-plugins 0.3.5\n    Uninstalling mdit-py-plugins-0.3.5:\n      Successfully uninstalled mdit-py-plugins-0.3.5\nSuccessfully installed automatic-prompt-engineer-1.0 ffmpy-0.3.0 gradio-3.30.0 gradio-client-0.2.4 httpcore-0.17.0 httpx-0.24.0 linkify-it-py-2.0.2 mdit-py-plugins-0.3.3 openai-0.27.6 python-multipart-0.0.6 semantic-version-2.10.0 uc-micro-py-1.0.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.api_key = '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'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-15T09:21:59.660352Z",
          "iopub.execute_input": "2023-05-15T09:21:59.660749Z",
          "iopub.status.idle": "2023-05-15T09:21:59.898507Z",
          "shell.execute_reply.started": "2023-05-15T09:21:59.660718Z",
          "shell.execute_reply": "2023-05-15T09:21:59.897563Z"
        },
        "trusted": true,
        "id": "092D2tvecuk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_template = \\\n",
        "\"\"\"Instruction: [PROMPT]\n",
        "Input: [INPUT]\n",
        "Output: [OUTPUT]\"\"\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-15T09:22:02.476258Z",
          "iopub.execute_input": "2023-05-15T09:22:02.478729Z",
          "iopub.status.idle": "2023-05-15T09:22:02.483385Z",
          "shell.execute_reply.started": "2023-05-15T09:22:02.478678Z",
          "shell.execute_reply": "2023-05-15T09:22:02.482445Z"
        },
        "trusted": true,
        "id": "vNL-sbKxcuk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use APE to find prompts\n",
        "from automatic_prompt_engineer import ape\n",
        "\n",
        "result, demo_fn = ape.simple_ape(\n",
        "    dataset=(train_data1, y_train_data),\n",
        "    eval_template=eval_template,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-15T11:39:12.599882Z",
          "iopub.execute_input": "2023-05-15T11:39:12.600281Z",
          "iopub.status.idle": "2023-05-15T11:39:41.425326Z",
          "shell.execute_reply.started": "2023-05-15T11:39:12.600251Z",
          "shell.execute_reply": "2023-05-15T11:39:41.424275Z"
        },
        "trusted": true,
        "id": "XD52tNVkcuk9",
        "outputId": "d499e2bb-7d42-47e1-94f7-c307ecbe7b2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Generating prompts...\n[GPT_forward] Generating 50 completions, split into 1 batches of size 2000\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|██████████| 1/1 [00:02<00:00,  3.00s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Model returned 50 prompts. Deduplicating...\nDeduplicated to 50 prompts.\nEvaluating prompts...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Evaluating prompts: 100%|██████████| 20/20 [00:25<00:00,  1.29s/it]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Finished evaluating.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-15T11:39:44.303892Z",
          "iopub.execute_input": "2023-05-15T11:39:44.304885Z",
          "iopub.status.idle": "2023-05-15T11:39:44.312439Z",
          "shell.execute_reply.started": "2023-05-15T11:39:44.304841Z",
          "shell.execute_reply": "2023-05-15T11:39:44.311354Z"
        },
        "trusted": true,
        "id": "JNKaB9nYcuk9",
        "outputId": "a61f40ac-c9a3-4ea9-ce55-beab3b8e16b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "score: prompt\n----------------\n-1.11:  produce an output of 1 if the input was a news article and 0 if it was not.\n-1.18:  \"input a URL\". The output should have been \"1\", indicating that the input was a valid URL.\n-1.19:  produce a 1 if the input is a news article and a 0 if the input is not a news article.\n-1.21:  give a 1 for any input that contained the word \"earthquake\" and a 0 for any input that did not contain the word \"earthquake.\"\n-1.32:  input a string of text and output a 1 if the text contained a link and a 0 if the text did not contain a link.\n-1.36:  input a message and get a response of 0 or 1. 0 indicates that the message is not positive, and 1 indicates that the message is positive. Based on the given input-output pairs, it seems that the instruction is to input a message and\n-1.37:  input a URL and output a 1 if the URL is valid and a 0 if the URL is invalid.\n-1.40:  \"Input a string of text and output a 1 if the text contains the word 'quake' and a 0 if the text does not contain the word 'quake'.\"\n-1.51:  \"write a program that outputs a 1 if the input contains the word 'quake' and a 0 if the input does not contain the word 'quake'.\"\n-1.59:  \"return 1 if the input contains the word 'quake' and 0 otherwise.\"\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_auto=[]\n",
        "for i in test_data['input_text']:\n",
        "    prompt_text = '''Input: {} Output:'''.format(i)\n",
        "\n",
        "    prompt = tokenizer(prompt_text, truncation=True, return_tensors='pt')\n",
        "    prompt = {key: value.to(device) for key, value in prompt.items()}\n",
        "    out = gpt.generate(**prompt, max_length=1, top_k=40, top_p=0.9, temperature=0.3, do_sample=False, repetition_penalty = 1.1, num_beams=1, pad_token_id=0)\n",
        "    y_hat = tokenizer.decode(out[0][-1]).strip();\n",
        "#     print('y_hat', y_hat)\n",
        "#     print(tokenizer.decode(out[0]))\n",
        "    predictions_auto.append(int(y_hat) if y_hat.isdigit() else None)    "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-15T11:51:36.034673Z",
          "iopub.execute_input": "2023-05-15T11:51:36.035039Z",
          "iopub.status.idle": "2023-05-15T11:57:40.944540Z",
          "shell.execute_reply.started": "2023-05-15T11:51:36.035009Z",
          "shell.execute_reply": "2023-05-15T11:57:40.943582Z"
        },
        "trusted": true,
        "id": "0pnmQsRecuk9",
        "outputId": "35daf435-a7b8-4d3b-c87a-d44bcf612e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Input length of input_ids is 20, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 46, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 54, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 24, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 20, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 12, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 43, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 43, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 54, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 26, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 57, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 17, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 48, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 58, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 9, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 34, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 55, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 16, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 55, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 13, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 9, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 27, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 57, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 45, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 22, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 27, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 15, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 23, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 24, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 13, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 43, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 34, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 54, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 26, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 17, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 26, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 20, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 54, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 7, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 51, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 26, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 13, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 18, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 46, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 27, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 13, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 24, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 45, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 56, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 34, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 21, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 26, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 14, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 26, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 34, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 16, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 49, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 16, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 46, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 52, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 43, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 22, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 30, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 26, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 15, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 69, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 22, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 50, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 43, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 46, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 16, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 26, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 60, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 18, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 50, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 51, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 17, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 23, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 34, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 49, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 59, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 14, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 20, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 47, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 16, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 17, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 20, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 24, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 24, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 27, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 48, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 26, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 56, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 47, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 58, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 16, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 56, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 18, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 19, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 16, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 26, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 24, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 16, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 45, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 22, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 51, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 47, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 25, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 27, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 50, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 50, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 26, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 30, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 34, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 51, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 55, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 45, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 34, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 51, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 56, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 22, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 24, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 24, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 45, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 12, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 53, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 12, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 55, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 50, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 20, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 30, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 12, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 17, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 14, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 16, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 57, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 51, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 15, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 27, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 20, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 23, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 58, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 21, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 46, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 50, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 30, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 26, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 55, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 26, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 24, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 23, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 27, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 23, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 20, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 56, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 46, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 30, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 49, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 12, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 49, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 24, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 55, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 58, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 21, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 22, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 45, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 48, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 52, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 47, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 56, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 25, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 22, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 26, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 19, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 47, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 30, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 24, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 25, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 11, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 9, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 23, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 34, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 18, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 51, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 62, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 21, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 15, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 26, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 55, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 10, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 23, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 60, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 26, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 14, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 54, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 57, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 46, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 56, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 34, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 46, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 20, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 19, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 46, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 16, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 27, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 34, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 46, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 30, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 24, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 43, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 48, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 21, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 17, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 50, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 48, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 20, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 48, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 23, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 20, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 59, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 51, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 51, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 18, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 21, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 46, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 23, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 47, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 15, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 19, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 25, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 24, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 55, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 20, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 59, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 48, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 50, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 19, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 23, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 22, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 47, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 25, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 53, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 26, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 27, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 48, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 48, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 46, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 52, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 64, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 17, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 19, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 59, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 43, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 14, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 46, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 27, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 51, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 55, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 19, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 43, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 34, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 15, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 14, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 19, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 43, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 45, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 54, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 61, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 48, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 53, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 30, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 46, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 26, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 52, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 10, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 66, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 17, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 30, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 30, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 19, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 48, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 25, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 51, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 46, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 30, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 34, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 49, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 30, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 43, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 53, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 12, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 14, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 43, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 17, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 14, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 25, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 23, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 30, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 27, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 27, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 45, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 23, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 45, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 12, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 34, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 43, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 30, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 25, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 51, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 61, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 34, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 19, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 25, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 24, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 22, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 22, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 47, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 17, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 53, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 53, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 45, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 21, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 46, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 47, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 27, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 47, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 47, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 25, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 47, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 47, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 23, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 47, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 13, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 23, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 8, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 23, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 49, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 48, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 47, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 54, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 17, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 15, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 53, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 53, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 67, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 43, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 34, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 45, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 24, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 51, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 59, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 46, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 43, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 76, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 50, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 34, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 20, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 50, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 24, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 19, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 43, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 19, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 13, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 45, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 34, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 21, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 24, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 45, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 57, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 22, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 58, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 30, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 34, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 53, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 24, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 48, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 22, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 38, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 14, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 34, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 56, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 20, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 9, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 52, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 14, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 55, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 46, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 20, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 22, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 20, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 52, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 15, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 43, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 18, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 36, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 12, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 41, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 35, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 18, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 30, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 8, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 50, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 27, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 40, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 33, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 12, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 13, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 30, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 39, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 10, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 28, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 27, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 49, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 42, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 31, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 27, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 25, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 29, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 44, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 17, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 32, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 37, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 52, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\nInput length of input_ids is 14, but `max_length` is set to 1. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define evaluation function\n",
        "from sklearn.metrics import accuracy_score\n",
        "def evaluate(prediction, target):\n",
        "    return accuracy_score(prediction, target)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-15T11:58:00.753328Z",
          "iopub.execute_input": "2023-05-15T11:58:00.753918Z",
          "iopub.status.idle": "2023-05-15T11:58:00.760340Z",
          "shell.execute_reply.started": "2023-05-15T11:58:00.753884Z",
          "shell.execute_reply": "2023-05-15T11:58:00.759375Z"
        },
        "trusted": true,
        "id": "oYJIqFbMcuk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "evaluate(np.zeros(len(y_test_data)),y_test_data)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-15T11:58:01.530987Z",
          "iopub.execute_input": "2023-05-15T11:58:01.531694Z",
          "iopub.status.idle": "2023-05-15T11:58:01.539985Z",
          "shell.execute_reply.started": "2023-05-15T11:58:01.531661Z",
          "shell.execute_reply": "2023-05-15T11:58:01.539031Z"
        },
        "trusted": true,
        "id": "-IuaucTOcuk-",
        "outputId": "7d36c71d-9253-4fe0-854c-c5b1caa975ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 48,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.5590551181102362"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "or2mXwMPcuk-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}